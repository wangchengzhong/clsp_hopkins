该项目的目标是为 48 个单词的词汇构建一个孤立单词语音识别器。您将构建两个基于（循环）神经网络的识别器，一个使用基于量化语音的表示，另一个使用连续值梅尔频率倒谱系数 (MFCC)。

每个语音样本（即 *.wav 文件）都经过处理，每 10 毫秒提取一次频谱特征，并且生成的特征向量均已量化为 256 个离散标签之一。这些将构成您的离散值观察序列 Y。

您将首先构建一个神经网络，其输入为 Y，输出为字母序列 𝑙𝑙1, 𝑙𝑙2, … , 𝑙𝑙|𝑊𝑊|对应于其单词标签W的拼写。

然后，您将使用所有训练数据和 CTC 损失来训练您的神经网络，这将最大化序列 𝑙𝑙1、𝑙𝑙2、…、𝑙𝑙|𝑊𝑊| 的所有时间对齐的总后验概率（给定 Y）。玩具。

然后，您将使用神经网络计算给定每个测试语音样本的 48 个单词中每个单词的后验概率（或 CTC 损失），并选择最大化器（或 CTC 损失）。

最小化器）作为你的输出。

最后，您将计算系统对测试数据的平均识别精度。

下面的说明是假设您将使用 TA 提供的代码框架在 PyTorch 中实现识别器而编写的。您也可以自己从头开始实施。

1. 训练和测试数据文件：
有一个文件枚举了 256 个簇标签的可能值，即声学处理器的（量化）输出。

clsp.lblnames 包含 256 个两字符长的标签名称，每行一个，总共 256 行，加上文件顶部的标题行。 [总计：257 行] 有四个训练数据文件，如下所述。

clsp.trnscr 是由演讲者朗读的“脚本”，其演讲包含训练数据。词汇表中的 48 个单词均以某种随机顺序呈现给演讲者。该脚本文件包含每个单词至少 10 个、最多 25 个示例，总共 798 行数据，加上文件顶部的标题行。 [总计：799 行。] 

clsp.trnwav 包含与上述脚本文件中每个单词的发音相对应的语音（波形）文件的名称。该文件共有 798 行，加上标题行。 [总计：799 行。] 您可能希望进一步将训练数据分为“训练”和“验证”集以进行神经网络训练

clsp.trnlbls 包含 Y，即与上述脚本文件中每个单词的发音相对应的处理后的语音。每行有一个长标签字符串，共有 798 行，加上该文件顶部的标题行。 [总计：799 行，106,785 个标签。] 

clsp.endpts 包含“终点”信息，或有关每个话语周围的前导和尾随沉默的信息。该信息以每行两个整数的形式编码，例如 i 和 j，以指示前导静音的最后一个标签位于位置 i，尾随静音的第一个标签位于位置 j，并且语音对应到标签文件中的第 (i + 1) 个到第 (j − 1) 个标签。同样，有 798 行数据，加上标题行。 [总计：799 行。] 最后，有两个测试数据文件：
 
clsp.devwav 包含与测试集中每个单词的发音相对应的语音（波形）文件的名称。该文件共有 393 行，加上标题行。 [总计：394 行。] 

clsp.devlbls 包含标签 Y，每行一个可变长度标签字符串，对应于测试集中每个单词的话语。该文件共有 393 行，加上标题行。 [总计：394 行，52,812 个标签。]

2. 构建主要识别器的步骤：

(1).创建 Pytorch DataLoader：修改文件 dataset.py 中提供的代码以加载数据集。使用每个单词的拼写作为其语音的输出标签序列。

用您选择的“沉默”符号填充两侧的拼写，让网络为沉默帧输出合适的标签。

（2）。创建 PyTorch 模型：修改 model.py 文件中提供的代码以创建您选择的 PyTorch 模型。建议使用 LSTM 模型，但您可以尝试使用 CNN 或 CNN 和 LSTM 的组合。模型的输出尺寸应为 Batch × InputLength × NumLetters。

（3）。训练 PyTorch 模型：使用 CTC 标准训练您的 PyTorch 模型。您可能希望在训练期间计算某些保留（即验证）集的 CTC 损失，以确保模型不会过度拟合。

（4）。构建单词识别器：经过训练的系统的输出应该为您提供每帧中每个字母的概率。创建一个识别器，使用这些概率从 48 个单词的词汇表中生成最可能的单词。

(a) 一种简单（“贪心”）的方法是，将每一帧最可能的字母作为输出符号，然后“压缩”重复的符号来拼写输出单词。

(b) 一种更复杂的方法是计算每个测试示例的每个沉默填充单词假设的内置 CTCLoss，并选择损失最低的单词作为该示例的输出。

5. 测试 PyTorch 模型：检查模型在训练数据本身上的准确性，以确保其正确训练。此外，请针对所提供的 393 个测试话语中的每一个提交您的词语假设。

3.对比系统

构建一个对比系统来探索主系统的替代方案：使用 MFCC 向量而不是提供的 256 个离散特征。您可以使用基于内置 Python 库的代码来计算 TA 提供的 MFCC。我们通常使用 25ms 的分析窗口和 10ms 的步长（即相邻窗口之间有 15ms 的重叠）来计算 40 维 MFCC。然而，调整这些超参数可能会有所帮助，看看什么最有效。为您的对比系统提交一份类似报告（参见上面标记为 ⇒ 的项目）。

4. 提交

在您的报告中提交主要系统和对比系统的以下内容。

⇒ 神经网络训练损失与迭代次数的关系图。如果您提供验证集来检查神经网络训练的进度，您可以选择在此图中包含其损失。

⇒ 对于测试数据中的每个话语，最有可能的单词的身份和置信度。

⇒ 您的源代码，以及有关运行每个模块所需的文件的大量文档，以及运行训练和测试模块的命令行（用法）。

• 您的代码应在运行最新版本的GNU/Linux 和PyTorch 的x86 64 计算机上运行。

最终提交的文件应该是包含上述所有内容的 tarball，具有明显的文件名和自述文件。